{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Q. Implement a program on Adversarial training, tangent distance, tangent prop and tangent classifier. [Any three to be implemented].**"
      ],
      "metadata": {
        "id": "t-xHTU9ISaTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def generate_adversarial_example(model, x, y, epsilon=0.1):\n",
        "    x.requires_grad = True\n",
        "    output = model(x)\n",
        "    loss = F.cross_entropy(output, y)\n",
        "    model.zero_grad()\n",
        "    loss.backward(retain_graph=True)\n",
        "    x_adv = x + epsilon * x.grad.sign()\n",
        "    return x_adv\n",
        "\n",
        "def tangent_distance(x1, x2, model):\n",
        "\n",
        "    x1.requires_grad = True\n",
        "    x2.requires_grad = True\n",
        "    output1 = model(x1)\n",
        "    output2 = model(x2)\n",
        "    grad1 = torch.autograd.grad(outputs=output1, inputs=x1, grad_outputs=torch.ones_like(output1), create_graph=True)[0]\n",
        "    grad2 = torch.autograd.grad(outputs=output2, inputs=x2, grad_outputs=torch.ones_like(output2), create_graph=True)[0]\n",
        "    dist = torch.norm(grad1 - grad2)\n",
        "    return dist\n",
        "\n",
        "def tangent_prop(model, x, y, learning_rate=0.001, epsilon=0.1):\n",
        "    x_adv = generate_adversarial_example(model, x, y, epsilon)\n",
        "\n",
        "    x_adv = x_adv.detach().requires_grad_(True)\n",
        "    output_adv = model(x_adv)\n",
        "    loss = F.cross_entropy(output_adv, y)\n",
        "    model.zero_grad()\n",
        "    loss.backward(retain_graph=True)\n",
        "    for param in model.parameters():\n",
        "        param.data -= learning_rate * param.grad.data\n",
        "    return model, loss\n",
        "\n",
        "def train_model(model, train_loader, epochs=5):\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for data, target in train_loader:\n",
        "            data, target = data.view(-1, 28*28), target\n",
        "            data, target = Variable(data), Variable(target)\n",
        "\n",
        "            x_adv = generate_adversarial_example(model, data, target)\n",
        "\n",
        "            model, loss = tangent_prop(model, data, target)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward(retain_graph=True)\n",
        "            optimizer.step()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item()}\")\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "model = SimpleNN()\n",
        "train_model(model, train_loader, epochs=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCV-aW38Rg2W",
        "outputId": "7851f71b-d636-4506-ce6d-f7e4f729a8e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.5123910307884216\n",
            "Epoch [2/5], Loss: 0.3119443953037262\n",
            "Epoch [3/5], Loss: 0.2703799903392792\n",
            "Epoch [4/5], Loss: 0.16539806127548218\n",
            "Epoch [5/5], Loss: 0.46896031498908997\n"
          ]
        }
      ]
    }
  ]
}